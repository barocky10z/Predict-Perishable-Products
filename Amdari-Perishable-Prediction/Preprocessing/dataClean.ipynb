{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd401dc9",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d51183",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a7c2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt     \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split    \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13252ad",
   "metadata": {},
   "source": [
    "### Load the datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1a75916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 5 datasets to be loaded with the following code\n",
    "prod_data = pd.read_csv(r\"C:\\Users\\Etteba\\OneDrive\\Documents\\DataSciencePortfolioProjects\\PredPerishProducts\\Amdari-Perishable-Prediction\\Datasets\\product_details.csv\")\n",
    "store_data = pd.read_csv(r\"C:\\Users\\Etteba\\OneDrive\\Documents\\DataSciencePortfolioProjects\\PredPerishProducts\\Amdari-Perishable-Prediction\\Datasets\\store_info.csv\")\n",
    "supplier_data = pd.read_csv(r\"C:\\Users\\Etteba\\OneDrive\\Documents\\DataSciencePortfolioProjects\\PredPerishProducts\\Amdari-Perishable-Prediction\\Datasets\\supplier_info.csv\")\n",
    "weather_data = pd.read_csv(r\"C:\\Users\\Etteba\\OneDrive\\Documents\\DataSciencePortfolioProjects\\PredPerishProducts\\Amdari-Perishable-Prediction\\Datasets\\weather_data.csv\")\n",
    "weekly_sales_data = pd.read_csv(r\"C:\\Users\\Etteba\\OneDrive\\Documents\\DataSciencePortfolioProjects\\PredPerishProducts\\Amdari-Perishable-Prediction\\Datasets\\weekly_sales.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb069a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Product_ID              Product_Name Product_Category  Shelf_Life_Days  \\\n",
      "0        1000    Whole Wheat Bread 800g           Bakery                4   \n",
      "1        1001       White Sandwich Loaf           Bakery                2   \n",
      "2        1002          Croissant 4-pack           Bakery                2   \n",
      "3        1003  Blueberry Muffins 6-pack           Bakery                4   \n",
      "4        1004    Chocolate Chip Cookies           Bakery                4   \n",
      "\n",
      "   Supplier_ID  \n",
      "0            4  \n",
      "1            8  \n",
      "2            5  \n",
      "3           10  \n",
      "4            7  \n",
      "   Store_ID      Region  Store_Size  Cold_Storage_Capacity\n",
      "0       500      London       12000                   3788\n",
      "1       501    Midlands        5000                   1086\n",
      "2       502  North East        4000                    998\n",
      "3       503    Midlands        5000                   1243\n",
      "4       504      London       10000                   3330\n",
      "   Supplier_ID              Supplier_Name  Lead_Time_Days  Supply_Capacity\n",
      "0            1         FreshFoods UK Ltd.               1            68047\n",
      "1            2     Quality Provisions Co.               2            35230\n",
      "2            3  FarmDirect Suppliers Ltd.               2            71976\n",
      "3            4     PremiumGoods Wholesale               3            48776\n",
      "4            5  LocalHarvest Distributors               2            11306\n",
      "  Week_Number      Region  Avg_Temperature  Rainfall  Holiday_Flag\n",
      "0    2024-W01    Midlands              7.4      32.1             0\n",
      "1    2024-W01  South East             10.5      15.7             0\n",
      "2    2024-W01  North West              6.8      28.5             1\n",
      "3    2024-W01      London              9.9      23.0             1\n",
      "4    2024-W01  South West             10.0      45.9             1\n",
      "  Week_Number  Product_ID  Store_ID  Units_Sold  Marketing_Spend  \\\n",
      "0    2024-W01        1000       500        4853           670.37   \n",
      "1    2024-W01        1001       500        4274          1089.62   \n",
      "2    2024-W01        1002       500        4215          1004.99   \n",
      "3    2024-W01        1003       500        5768           859.45   \n",
      "4    2024-W01        1004       500        3403           576.70   \n",
      "\n",
      "   Discount_Percent  Wastage_Units  Price  \n",
      "0                 0            718   2.46  \n",
      "1                 0            641   1.27  \n",
      "2                10            632   2.74  \n",
      "3                20            853   1.82  \n",
      "4                 0            503   3.46  \n"
     ]
    }
   ],
   "source": [
    "#Inspect the datasets\n",
    "print(prod_data.head(5))\n",
    "print(store_data.head(5))    \n",
    "print(supplier_data.head(5))\n",
    "print(weather_data.head(5))\n",
    "print(weekly_sales_data.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c06443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32 entries, 0 to 31\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Product_ID        32 non-null     int64 \n",
      " 1   Product_Name      32 non-null     object\n",
      " 2   Product_Category  32 non-null     object\n",
      " 3   Shelf_Life_Days   32 non-null     int64 \n",
      " 4   Supplier_ID       32 non-null     int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 1.4+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15 entries, 0 to 14\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   Store_ID               15 non-null     int64 \n",
      " 1   Region                 15 non-null     object\n",
      " 2   Store_Size             15 non-null     int64 \n",
      " 3   Cold_Storage_Capacity  15 non-null     int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 612.0+ bytes\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Supplier_ID      10 non-null     int64 \n",
      " 1   Supplier_Name    10 non-null     object\n",
      " 2   Lead_Time_Days   10 non-null     int64 \n",
      " 3   Supply_Capacity  10 non-null     int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 452.0+ bytes\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 364 entries, 0 to 363\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Week_Number      364 non-null    object \n",
      " 1   Region           364 non-null    object \n",
      " 2   Avg_Temperature  364 non-null    float64\n",
      " 3   Rainfall         364 non-null    float64\n",
      " 4   Holiday_Flag     364 non-null    int64  \n",
      "dtypes: float64(2), int64(1), object(2)\n",
      "memory usage: 14.3+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37440 entries, 0 to 37439\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Week_Number       37440 non-null  object \n",
      " 1   Product_ID        37440 non-null  int64  \n",
      " 2   Store_ID          37440 non-null  int64  \n",
      " 3   Units_Sold        37440 non-null  int64  \n",
      " 4   Marketing_Spend   37440 non-null  float64\n",
      " 5   Discount_Percent  37440 non-null  int64  \n",
      " 6   Wastage_Units     37440 non-null  int64  \n",
      " 7   Price             37440 non-null  float64\n",
      "dtypes: float64(2), int64(5), object(1)\n",
      "memory usage: 2.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Checkl the columns and data types of each dataset\n",
    "print(prod_data.info())\n",
    "print(store_data.info())\n",
    "print(supplier_data.info())\n",
    "print(weather_data.info())  \n",
    "print(weekly_sales_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2e48a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Product_ID', 'Product_Name', 'Product_Category', 'Shelf_Life_Days',\n",
      "       'Supplier_ID'],\n",
      "      dtype='object')\n",
      "Index(['Store_ID', 'Region', 'Store_Size', 'Cold_Storage_Capacity'], dtype='object')\n",
      "Index(['Supplier_ID', 'Supplier_Name', 'Lead_Time_Days', 'Supply_Capacity'], dtype='object')\n",
      "Index(['Week_Number', 'Region', 'Avg_Temperature', 'Rainfall', 'Holiday_Flag'], dtype='object')\n",
      "Index(['Week_Number', 'Product_ID', 'Store_ID', 'Units_Sold',\n",
      "       'Marketing_Spend', 'Discount_Percent', 'Wastage_Units', 'Price'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the column names to see if there are any common columns to merge on\n",
    "print(prod_data.columns)\n",
    "print(store_data.columns)\n",
    "print(supplier_data.columns)\n",
    "print(weather_data.columns)\n",
    "print(weekly_sales_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef258cb7",
   "metadata": {},
   "source": [
    "The result above shows that there are four common columns or keys we can use to merge the datasets: Product_ID, Supplier_ID, Region and Week_Number.\n",
    "\n",
    "Hence we will merge the datasets logically in this order:\n",
    "\n",
    "* step 1: Merge Weekly Sales with the Product Details via Product_ID to get a new dataset called merged_df\n",
    "* step 2: merged_df would be merged with supplier_info (via Supplier_ID)\n",
    "* step 3: merged_df with store_info (via Store_ID)\n",
    "* step 4: merged_df with with weather_data (via Week_Number and Region) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a250343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Week_Number  Product_ID  Store_ID  Units_Sold  Marketing_Spend  \\\n",
      "0    2024-W01        1000       500        4853           670.37   \n",
      "1    2024-W01        1001       500        4274          1089.62   \n",
      "2    2024-W01        1002       500        4215          1004.99   \n",
      "3    2024-W01        1003       500        5768           859.45   \n",
      "4    2024-W01        1004       500        3403           576.70   \n",
      "5    2024-W01        1005       500        3757           937.48   \n",
      "6    2024-W01        1006       500        5562           546.51   \n",
      "7    2024-W01        1007       500        2957           984.57   \n",
      "8    2024-W01        1008       500        5925           641.34   \n",
      "9    2024-W01        1009       500        7494           853.40   \n",
      "\n",
      "   Discount_Percent  Wastage_Units  Price              Product_Name  \\\n",
      "0                 0            718   2.46    Whole Wheat Bread 800g   \n",
      "1                 0            641   1.27       White Sandwich Loaf   \n",
      "2                10            632   2.74          Croissant 4-pack   \n",
      "3                20            853   1.82  Blueberry Muffins 6-pack   \n",
      "4                 0            503   3.46    Chocolate Chip Cookies   \n",
      "5                 0            556   3.72             Bagels 6-pack   \n",
      "6                 0            834   2.27     Cinnamon Rolls 4-pack   \n",
      "7                 0            413   1.71           French Baguette   \n",
      "8                 0            876   2.82             Scones 4-pack   \n",
      "9                 0           1124   1.41         Banana Bread Loaf   \n",
      "\n",
      "  Product_Category  ...  Supplier_ID              Supplier_Name  \\\n",
      "0           Bakery  ...          4.0     PremiumGoods Wholesale   \n",
      "1           Bakery  ...          8.0   TrustedSource Provisions   \n",
      "2           Bakery  ...          5.0  LocalHarvest Distributors   \n",
      "3           Bakery  ...         10.0     BestQuality Foods Ltd.   \n",
      "4           Bakery  ...          7.0     SwiftDelivery Foods UK   \n",
      "5           Bakery  ...          8.0   TrustedSource Provisions   \n",
      "6           Bakery  ...          4.0     PremiumGoods Wholesale   \n",
      "7           Bakery  ...          8.0   TrustedSource Provisions   \n",
      "8           Bakery  ...          6.0     OrganicChoice Partners   \n",
      "9           Bakery  ...          2.0     Quality Provisions Co.   \n",
      "\n",
      "  Lead_Time_Days  Supply_Capacity  Region Store_Size  Cold_Storage_Capacity  \\\n",
      "0            3.0          48776.0  London      12000                   3788   \n",
      "1            3.0          46959.0  London      12000                   3788   \n",
      "2            2.0          11306.0  London      12000                   3788   \n",
      "3            2.0          53748.0  London      12000                   3788   \n",
      "4            2.0          59474.0  London      12000                   3788   \n",
      "5            3.0          46959.0  London      12000                   3788   \n",
      "6            3.0          48776.0  London      12000                   3788   \n",
      "7            3.0          46959.0  London      12000                   3788   \n",
      "8            2.0          31776.0  London      12000                   3788   \n",
      "9            2.0          35230.0  London      12000                   3788   \n",
      "\n",
      "   Avg_Temperature  Rainfall  Holiday_Flag  \n",
      "0              9.9      23.0             1  \n",
      "1              9.9      23.0             1  \n",
      "2              9.9      23.0             1  \n",
      "3              9.9      23.0             1  \n",
      "4              9.9      23.0             1  \n",
      "5              9.9      23.0             1  \n",
      "6              9.9      23.0             1  \n",
      "7              9.9      23.0             1  \n",
      "8              9.9      23.0             1  \n",
      "9              9.9      23.0             1  \n",
      "\n",
      "[10 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Merge datasets logically ---\n",
    "\n",
    "# Step 1: Merge Weekly Sales with Product Details\n",
    "merged_df = weekly_sales_data.merge(prod_data, on='Product_ID', how='left')\n",
    "\n",
    "# Step 2: Merge with Supplier Info (via Supplier_ID)\n",
    "merged_df = merged_df.merge(supplier_data, on='Supplier_ID', how='left')\n",
    "\n",
    "# Step 3: Merge with Store Info (via Store_ID)\n",
    "merged_df = merged_df.merge(store_data, on='Store_ID', how='left')\n",
    "\n",
    "# Step 4: Merge with Weather Data (via Week_Number and Region)\n",
    "merged_df = merged_df.merge(weather_data, on=['Week_Number', 'Region'], how='left')\n",
    "\n",
    "# Lets inspect the first 10 rows of the final merged dataset\n",
    "print(merged_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b9fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Export to CSV ---\n",
    "output_path = \"merged_dataset.csv\"\n",
    "merged_df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perishvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
